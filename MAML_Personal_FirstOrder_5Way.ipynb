{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2251edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as keras_backend\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import preprocessing\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproduction\n",
    "seed = 333\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472cb76",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe70dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "project_path = r\"C:\\Users\\ktub2\\Dropbox\\family\\Kausthubh\\UW Madison\\Coursework\\ECE 539\\Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf2d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for validation.\n"
     ]
    }
   ],
   "source": [
    "omni_path = join(project_path, r\"omniglot-processed-5-train\")\n",
    "omni_train_datasets = dict()\n",
    "omni_val_datasets = dict()\n",
    "\n",
    "for name in listdir(omni_path):\n",
    "    path = join(omni_path, name)\n",
    "    if isdir(path):\n",
    "        omni_train_datasets[name] = preprocessing.image_dataset_from_directory(path, label_mode='categorical',\n",
    "                                                             color_mode='grayscale', batch_size=1000, image_size=(28,28),\n",
    "                                                             seed=seed, validation_split=0.25, subset=\"training\")\n",
    "        omni_val_datasets[name] = preprocessing.image_dataset_from_directory(path, label_mode='categorical',\n",
    "                                                             color_mode='grayscale', batch_size=1000, image_size=(28,28),\n",
    "                                                             seed=seed, validation_split=0.25, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6bb8034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 28, 28, 1) (25, 5)\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_tensors(dataset):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for x, y in dataset:\n",
    "        xs.extend(x)\n",
    "        ys.extend(y)\n",
    "    # xs = np.array(xs)\n",
    "    # ys = np.array(ys)\n",
    "    return tf.convert_to_tensor(xs), tf.convert_to_tensor(ys)\n",
    "\n",
    "xs, ys = dataset_to_tensors(omni_val_datasets['Grantha'])\n",
    "print(xs.shape, ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c78cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n",
      "Train dataset converted\n",
      "Val dataset converted\n"
     ]
    }
   ],
   "source": [
    "omni_train_data = []\n",
    "omni_train_labels = []\n",
    "omni_val_data = []\n",
    "omni_val_labels = []\n",
    "for i in omni_train_datasets.keys():\n",
    "    xs,ys = dataset_to_tensors(omni_train_datasets[i])\n",
    "    omni_train_data.append(xs)\n",
    "    omni_train_labels.append(ys)\n",
    "    print('Train dataset converted')\n",
    "    xs,ys = dataset_to_tensors(omni_val_datasets[i])\n",
    "    omni_val_data.append(xs)\n",
    "    omni_val_labels.append(ys)\n",
    "    print('Val dataset converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f350b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_datasets = []\n",
    "for i in range(len(omni_train_data)):\n",
    "    if(len(omni_val_data[i]) == 25):\n",
    "        complete_datasets.append( (omni_train_data[i],omni_train_labels[i],omni_val_data[i],omni_val_labels[i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94d25c",
   "metadata": {},
   "source": [
    "### Model definition and relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d54fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    relu_initializer = tf.keras.initializers.HeNormal()\n",
    "    softmax_initializer = tf.keras.initializers.GlorotNormal()\n",
    "    \n",
    "    inputs = keras.Input(shape=(28,28,1))\n",
    "    for i in range(4):\n",
    "        if(i == 0):\n",
    "            x = layers.Conv2D(64, (3,3), kernel_initializer=relu_initializer, bias_initializer='zeros', \n",
    "                              activation='relu', padding='same')(inputs)\n",
    "        else:\n",
    "            x = layers.Conv2D(64, (3,3), kernel_initializer=relu_initializer, bias_initializer='zeros', \n",
    "                              activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(5, kernel_initializer=softmax_initializer)(x)\n",
    "    outputs = layers.Softmax()(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='maml_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3439aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, x, y, loss_fn=keras.losses.CategoricalCrossentropy()):\n",
    "    logits = model(x)\n",
    "    loss = loss_fn(y, logits)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b78b0d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"maml_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "softmax_3 (Softmax)          (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 112,773\n",
      "Trainable params: 112,261\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "meow = create_model()\n",
    "meow.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf2e87",
   "metadata": {},
   "source": [
    "### Meta Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "791266b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............\n",
      "Gradient check: -0.19087121\n",
      "Meta Update: Epoch Number 0\n",
      "Avg. Loss: tf.Tensor(11.727994, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.0\n",
      "Meta Update: Epoch Number 1\n",
      "Avg. Loss: tf.Tensor(11.831819, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -1.1746604\n",
      "Meta Update: Epoch Number 2\n",
      "Avg. Loss: tf.Tensor(11.281799, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.0\n",
      "Meta Update: Epoch Number 3\n",
      "Avg. Loss: tf.Tensor(10.944671, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.46185672\n",
      "Meta Update: Epoch Number 4\n",
      "Avg. Loss: tf.Tensor(11.407431, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.84826374\n",
      "Meta Update: Epoch Number 5\n",
      "Avg. Loss: tf.Tensor(10.719892, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.075252816\n",
      "Meta Update: Epoch Number 6\n",
      "Avg. Loss: tf.Tensor(10.19472, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.63437015\n",
      "Meta Update: Epoch Number 7\n",
      "Avg. Loss: tf.Tensor(10.326582, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.00057226\n",
      "Meta Update: Epoch Number 8\n",
      "Avg. Loss: tf.Tensor(10.275459, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.49129647\n",
      "Meta Update: Epoch Number 9\n",
      "Avg. Loss: tf.Tensor(9.295702, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.054740503\n",
      "Meta Update: Epoch Number 10\n",
      "Avg. Loss: tf.Tensor(9.173411, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.0\n",
      "Meta Update: Epoch Number 11\n",
      "Avg. Loss: tf.Tensor(8.671307, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.13717358\n",
      "Meta Update: Epoch Number 12\n",
      "Avg. Loss: tf.Tensor(8.905995, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.18807383\n",
      "Meta Update: Epoch Number 13\n",
      "Avg. Loss: tf.Tensor(7.005904, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.5926208\n",
      "Meta Update: Epoch Number 14\n",
      "Avg. Loss: tf.Tensor(7.544, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.45503265\n",
      "Meta Update: Epoch Number 15\n",
      "Avg. Loss: tf.Tensor(7.3459425, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.20315167\n",
      "Meta Update: Epoch Number 16\n",
      "Avg. Loss: tf.Tensor(5.6319075, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.076995\n",
      "Meta Update: Epoch Number 17\n",
      "Avg. Loss: tf.Tensor(6.656663, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.20152208\n",
      "Meta Update: Epoch Number 18\n",
      "Avg. Loss: tf.Tensor(5.034074, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 1.4699172\n",
      "Meta Update: Epoch Number 19\n",
      "Avg. Loss: tf.Tensor(4.1332827, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.042983726\n",
      "Meta Update: Epoch Number 20\n",
      "Avg. Loss: tf.Tensor(3.3979628, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.054464772\n",
      "Meta Update: Epoch Number 21\n",
      "Avg. Loss: tf.Tensor(3.4219685, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.4095204\n",
      "Meta Update: Epoch Number 22\n",
      "Avg. Loss: tf.Tensor(3.6867213, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -1.689492\n",
      "Meta Update: Epoch Number 23\n",
      "Avg. Loss: tf.Tensor(3.8122551, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.12346244\n",
      "Meta Update: Epoch Number 24\n",
      "Avg. Loss: tf.Tensor(3.1405647, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.3828721\n",
      "Meta Update: Epoch Number 25\n",
      "Avg. Loss: tf.Tensor(2.1217945, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.12916008\n",
      "Meta Update: Epoch Number 26\n",
      "Avg. Loss: tf.Tensor(3.2574697, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.16460314\n",
      "Meta Update: Epoch Number 27\n",
      "Avg. Loss: tf.Tensor(2.1631887, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.15963756\n",
      "Meta Update: Epoch Number 28\n",
      "Avg. Loss: tf.Tensor(2.2945492, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.0022992603\n",
      "Meta Update: Epoch Number 29\n",
      "Avg. Loss: tf.Tensor(2.346619, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.16016856\n",
      "Meta Update: Epoch Number 30\n",
      "Avg. Loss: tf.Tensor(2.3876672, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.08033928\n",
      "Meta Update: Epoch Number 31\n",
      "Avg. Loss: tf.Tensor(1.912783, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.02433218\n",
      "Meta Update: Epoch Number 32\n",
      "Avg. Loss: tf.Tensor(1.8915663, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.51381063\n",
      "Meta Update: Epoch Number 33\n",
      "Avg. Loss: tf.Tensor(2.1035037, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.20609297\n",
      "Meta Update: Epoch Number 34\n",
      "Avg. Loss: tf.Tensor(2.211882, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.44150376\n",
      "Meta Update: Epoch Number 35\n",
      "Avg. Loss: tf.Tensor(2.2301514, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.101852626\n",
      "Meta Update: Epoch Number 36\n",
      "Avg. Loss: tf.Tensor(1.8677464, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.05026503\n",
      "Meta Update: Epoch Number 37\n",
      "Avg. Loss: tf.Tensor(2.1271825, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.28468406\n",
      "Meta Update: Epoch Number 38\n",
      "Avg. Loss: tf.Tensor(1.9027774, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.03668631\n",
      "Meta Update: Epoch Number 39\n",
      "Avg. Loss: tf.Tensor(1.4962431, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.002181396\n",
      "Meta Update: Epoch Number 40\n",
      "Avg. Loss: tf.Tensor(1.7582852, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.04308138\n",
      "Meta Update: Epoch Number 41\n",
      "Avg. Loss: tf.Tensor(1.3725803, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.0075042695\n",
      "Meta Update: Epoch Number 42\n",
      "Avg. Loss: tf.Tensor(1.596677, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.20820093\n",
      "Meta Update: Epoch Number 43\n",
      "Avg. Loss: tf.Tensor(1.8250078, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.0067763925\n",
      "Meta Update: Epoch Number 44\n",
      "Avg. Loss: tf.Tensor(1.7905337, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.14154175\n",
      "Meta Update: Epoch Number 45\n",
      "Avg. Loss: tf.Tensor(2.0044467, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.15396678\n",
      "Meta Update: Epoch Number 46\n",
      "Avg. Loss: tf.Tensor(1.5481664, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.15274051\n",
      "Meta Update: Epoch Number 47\n",
      "Avg. Loss: tf.Tensor(1.6281807, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.09832333\n",
      "Meta Update: Epoch Number 48\n",
      "Avg. Loss: tf.Tensor(2.0119226, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.099997684\n",
      "Meta Update: Epoch Number 49\n",
      "Avg. Loss: tf.Tensor(1.5010319, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.13663392\n",
      "Meta Update: Epoch Number 50\n",
      "Avg. Loss: tf.Tensor(1.3315579, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.3103166\n",
      "Meta Update: Epoch Number 51\n",
      "Avg. Loss: tf.Tensor(1.5776278, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.14886262\n",
      "Meta Update: Epoch Number 52\n",
      "Avg. Loss: tf.Tensor(1.94981, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.030530121\n",
      "Meta Update: Epoch Number 53\n",
      "Avg. Loss: tf.Tensor(1.4842857, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.20325899\n",
      "Meta Update: Epoch Number 54\n",
      "Avg. Loss: tf.Tensor(1.5332615, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.034124956\n",
      "Meta Update: Epoch Number 55\n",
      "Avg. Loss: tf.Tensor(1.4977449, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.085590966\n",
      "Meta Update: Epoch Number 56\n",
      "Avg. Loss: tf.Tensor(2.096782, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.31429705\n",
      "Meta Update: Epoch Number 57\n",
      "Avg. Loss: tf.Tensor(1.8382522, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.12713505\n",
      "Meta Update: Epoch Number 58\n",
      "Avg. Loss: tf.Tensor(1.5034083, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.047667682\n",
      "Meta Update: Epoch Number 59\n",
      "Avg. Loss: tf.Tensor(1.4938128, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.017881578\n",
      "Meta Update: Epoch Number 60\n",
      "Avg. Loss: tf.Tensor(1.6158952, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.09467716\n",
      "Meta Update: Epoch Number 61\n",
      "Avg. Loss: tf.Tensor(1.5275244, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.13775282\n",
      "Meta Update: Epoch Number 62\n",
      "Avg. Loss: tf.Tensor(1.4426776, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.013530716\n",
      "Meta Update: Epoch Number 63\n",
      "Avg. Loss: tf.Tensor(1.6126878, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............\n",
      "Gradient check: 0.26414275\n",
      "Meta Update: Epoch Number 64\n",
      "Avg. Loss: tf.Tensor(1.3530607, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.076939546\n",
      "Meta Update: Epoch Number 65\n",
      "Avg. Loss: tf.Tensor(1.4325049, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.19011576\n",
      "Meta Update: Epoch Number 66\n",
      "Avg. Loss: tf.Tensor(1.5181463, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.06493834\n",
      "Meta Update: Epoch Number 67\n",
      "Avg. Loss: tf.Tensor(1.5008001, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.029792495\n",
      "Meta Update: Epoch Number 68\n",
      "Avg. Loss: tf.Tensor(1.4485794, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.08597098\n",
      "Meta Update: Epoch Number 69\n",
      "Avg. Loss: tf.Tensor(1.4065646, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.15754482\n",
      "Meta Update: Epoch Number 70\n",
      "Avg. Loss: tf.Tensor(2.0657508, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.073516175\n",
      "Meta Update: Epoch Number 71\n",
      "Avg. Loss: tf.Tensor(1.5376245, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.07156929\n",
      "Meta Update: Epoch Number 72\n",
      "Avg. Loss: tf.Tensor(1.79199, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.06959739\n",
      "Meta Update: Epoch Number 73\n",
      "Avg. Loss: tf.Tensor(1.341611, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.03618794\n",
      "Meta Update: Epoch Number 74\n",
      "Avg. Loss: tf.Tensor(1.4901867, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.2334128\n",
      "Meta Update: Epoch Number 75\n",
      "Avg. Loss: tf.Tensor(1.4365097, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.009430286\n",
      "Meta Update: Epoch Number 76\n",
      "Avg. Loss: tf.Tensor(1.476325, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.005371988\n",
      "Meta Update: Epoch Number 77\n",
      "Avg. Loss: tf.Tensor(1.2938459, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.050538458\n",
      "Meta Update: Epoch Number 78\n",
      "Avg. Loss: tf.Tensor(1.557174, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.008569726\n",
      "Meta Update: Epoch Number 79\n",
      "Avg. Loss: tf.Tensor(1.4436932, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.09655458\n",
      "Meta Update: Epoch Number 80\n",
      "Avg. Loss: tf.Tensor(1.722082, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.111899346\n",
      "Meta Update: Epoch Number 81\n",
      "Avg. Loss: tf.Tensor(1.402289, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.02604555\n",
      "Meta Update: Epoch Number 82\n",
      "Avg. Loss: tf.Tensor(1.2380952, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.011145264\n",
      "Meta Update: Epoch Number 83\n",
      "Avg. Loss: tf.Tensor(1.3730586, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.05521625\n",
      "Meta Update: Epoch Number 84\n",
      "Avg. Loss: tf.Tensor(1.5678993, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.037321866\n",
      "Meta Update: Epoch Number 85\n",
      "Avg. Loss: tf.Tensor(1.4055043, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.021074006\n",
      "Meta Update: Epoch Number 86\n",
      "Avg. Loss: tf.Tensor(1.2696444, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.069187686\n",
      "Meta Update: Epoch Number 87\n",
      "Avg. Loss: tf.Tensor(1.330974, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.027337695\n",
      "Meta Update: Epoch Number 88\n",
      "Avg. Loss: tf.Tensor(1.595244, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.0051139398\n",
      "Meta Update: Epoch Number 89\n",
      "Avg. Loss: tf.Tensor(1.3139095, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.032446317\n",
      "Meta Update: Epoch Number 90\n",
      "Avg. Loss: tf.Tensor(1.2811579, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.0040213726\n",
      "Meta Update: Epoch Number 91\n",
      "Avg. Loss: tf.Tensor(1.3084823, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.007193499\n",
      "Meta Update: Epoch Number 92\n",
      "Avg. Loss: tf.Tensor(1.3875991, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.03384646\n",
      "Meta Update: Epoch Number 93\n",
      "Avg. Loss: tf.Tensor(1.5051748, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.034039926\n",
      "Meta Update: Epoch Number 94\n",
      "Avg. Loss: tf.Tensor(1.208286, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.04854349\n",
      "Meta Update: Epoch Number 95\n",
      "Avg. Loss: tf.Tensor(1.2613014, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.06543285\n",
      "Meta Update: Epoch Number 96\n",
      "Avg. Loss: tf.Tensor(1.3742726, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: 0.004368212\n",
      "Meta Update: Epoch Number 97\n",
      "Avg. Loss: tf.Tensor(1.0384464, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.11651649\n",
      "Meta Update: Epoch Number 98\n",
      "Avg. Loss: tf.Tensor(1.2817767, shape=(), dtype=float32)\n",
      "...............\n",
      "Gradient check: -0.0017670393\n",
      "Meta Update: Epoch Number 99\n",
      "Avg. Loss: tf.Tensor(1.3141178, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "alpha = 0.1\n",
    "num_tasks = 15\n",
    "epochs = 100\n",
    "inner_epochs = 3\n",
    "i = 0\n",
    "all_losses = []\n",
    "optimizer_inner = keras.optimizers.SGD(learning_rate=alpha)\n",
    "optimizer_outer = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "model = create_model()\n",
    "model.compile()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    all_meta_gradients = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    for task in random.sample(complete_datasets,num_tasks):\n",
    "        train_data, train_labels, test_data, test_labels = task\n",
    "        \n",
    "        with tf.GradientTape() as test_tape:\n",
    "            model_copy = create_model()\n",
    "            model_copy.set_weights(model.get_weights())\n",
    "            model_copy.compile(optimizer=optimizer_inner, loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "            inner_history = model_copy.fit(train_data, train_labels, epochs=inner_epochs, verbose=0)\n",
    "            test_loss = compute_loss(model_copy, test_data, test_labels)\n",
    "            total_loss += test_loss\n",
    "            i += 1\n",
    "        print('.',end='')\n",
    "        meta_gradients = test_tape.gradient(test_loss, model_copy.trainable_weights)\n",
    "        all_meta_gradients.append(meta_gradients)\n",
    "      \n",
    "    print('')\n",
    "    print('Gradient check: '+str(all_meta_gradients[0][0][0,0,0,0].numpy()))\n",
    "    sum_meta_gradients = all_meta_gradients[0]\n",
    "    for i in range(1,len(all_meta_gradients)):\n",
    "        for j in range(len(all_meta_gradients[i])):\n",
    "            sum_meta_gradients[j] = sum_meta_gradients[j] + all_meta_gradients[i][j]\n",
    "    optimizer_outer.apply_gradients(zip(sum_meta_gradients, model.trainable_weights))\n",
    "    \n",
    "    print('Meta Update: Epoch Number '+str(epoch))\n",
    "    print('Avg. Loss: '+str(total_loss/(i)))\n",
    "    all_losses.append(total_loss/(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c94ff73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ktub2\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\ktub2\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models_5way/full_maml_model_5way\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('saved_models_5way/weights_maml_model_5way')\n",
    "model.save('saved_models_5way/full_maml_model_5way')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9484f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss VS Epochs for 5-way classification')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_losses, 'green')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Test Loss (Cross Entropy)')\n",
    "plt.title('Loss VS Epochs for 5-way classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d190ea6b",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70ada921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for validation.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 25 files for training.\n",
      "Found 100 files belonging to 5 classes.\n",
      "Using 75 files for validation.\n"
     ]
    }
   ],
   "source": [
    "omni_test_path = join(project_path, r\"omniglot-processed-5-test\")\n",
    "omni_test_train_datasets = dict()\n",
    "omni_test_val_datasets = dict()\n",
    "\n",
    "for name in listdir(omni_test_path):\n",
    "    path = join(omni_test_path, name)\n",
    "    if isdir(path):\n",
    "        omni_test_train_datasets[name] = preprocessing.image_dataset_from_directory(path, label_mode='categorical',\n",
    "                                                             color_mode='grayscale', batch_size=1000, image_size=(28,28),\n",
    "                                                             seed=seed, validation_split=0.75, subset=\"training\")\n",
    "        omni_test_val_datasets[name] = preprocessing.image_dataset_from_directory(path, label_mode='categorical',\n",
    "                                                             color_mode='grayscale', batch_size=1000, image_size=(28,28),\n",
    "                                                             seed=seed, validation_split=0.75, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7de44ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test train dataset converted\n",
      "Test val dataset converted\n",
      "Test train dataset converted\n",
      "Test val dataset converted\n",
      "Test train dataset converted\n",
      "Test val dataset converted\n",
      "Test train dataset converted\n",
      "Test val dataset converted\n",
      "Test train dataset converted\n",
      "Test val dataset converted\n"
     ]
    }
   ],
   "source": [
    "omni_test_train_data = []\n",
    "omni_test_train_labels = []\n",
    "omni_test_val_data = []\n",
    "omni_test_val_labels = []\n",
    "\n",
    "for i in omni_test_train_datasets.keys():\n",
    "    xs,ys = dataset_to_tensors(omni_test_train_datasets[i])\n",
    "    omni_test_train_data.append(xs)\n",
    "    omni_test_train_labels.append(ys)\n",
    "    print('Test train dataset converted')\n",
    "    xs,ys = dataset_to_tensors(omni_test_val_datasets[i])\n",
    "    omni_test_val_data.append(xs)\n",
    "    omni_test_val_labels.append(ys)\n",
    "    print('Test val dataset converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9ef4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanskrit_fine_tuning_data = omni_test_train_data[2]\n",
    "sanskrit_fine_tuning_labels = omni_test_train_labels[2]\n",
    "\n",
    "sanskrit_val_data = omni_test_val_data[2]\n",
    "sanskrit_val_labels = omni_test_val_labels[2]\n",
    "\n",
    "# model_sanskrit = create_model()\n",
    "# model_sanskrit.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1a1109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sanskrit = keras.models.load_model('saved_models_5way/full_maml_model_5way')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c96f9a81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 - 0s - loss: 7.1526e-07 - accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "1/1 - 0s - loss: 6.7711e-07 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "1/1 - 0s - loss: 6.6280e-07 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "1/1 - 0s - loss: 6.1989e-07 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "1/1 - 0s - loss: 5.8174e-07 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "1/1 - 0s - loss: 5.4836e-07 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "1/1 - 0s - loss: 5.1022e-07 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "1/1 - 0s - loss: 4.8161e-07 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "1/1 - 0s - loss: 4.5300e-07 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 - 0s - loss: 4.3392e-07 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 - 0s - loss: 4.1008e-07 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 - 0s - loss: 3.7670e-07 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 - 0s - loss: 3.5286e-07 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 - 0s - loss: 3.4332e-07 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 - 0s - loss: 3.3855e-07 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 - 0s - loss: 3.2902e-07 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 - 0s - loss: 3.1471e-07 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 - 0s - loss: 2.9564e-07 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 - 0s - loss: 2.7657e-07 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 - 0s - loss: 2.6226e-07 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 - 0s - loss: 2.4319e-07 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 - 0s - loss: 2.3365e-07 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 - 0s - loss: 2.2888e-07 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 - 0s - loss: 2.2411e-07 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 - 0s - loss: 2.0027e-07 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 - 0s - loss: 1.8597e-07 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 - 0s - loss: 1.6212e-07 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 - 0s - loss: 1.4305e-07 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 - 0s - loss: 1.3351e-07 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 - 0s - loss: 1.2398e-07 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 - 0s - loss: 1.2398e-07 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 - 0s - loss: 1.0490e-07 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 - 0s - loss: 1.0014e-07 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 - 0s - loss: 9.5367e-08 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 - 0s - loss: 9.0599e-08 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 - 0s - loss: 8.5831e-08 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 - 0s - loss: 8.1062e-08 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 - 0s - loss: 8.1062e-08 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 - 0s - loss: 8.1062e-08 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 - 0s - loss: 9.0599e-08 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 - 0s - loss: 8.1062e-08 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 - 0s - loss: 8.5831e-08 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 - 0s - loss: 7.6294e-08 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 - 0s - loss: 7.6294e-08 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 - 0s - loss: 7.6294e-08 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 - 0s - loss: 6.1989e-08 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 - 0s - loss: 6.1989e-08 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 - 0s - loss: 5.7220e-08 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 - 0s - loss: 5.7220e-08 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 - 0s - loss: 5.2452e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc46aad940>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sanskrit.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(), metrics='accuracy')\n",
    "model_sanskrit.fit(sanskrit_fine_tuning_data, sanskrit_fine_tuning_labels, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "935ae0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 42ms/step - loss: 1.8159 - accuracy: 0.2133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8159493207931519, 0.2133333384990692]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sanskrit.evaluate(sanskrit_val_data, sanskrit_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94bd62a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 2.2844 - accuracy: 0.3200\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.4061 - accuracy: 0.9600\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.0689 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 9.7761e-04 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 9.1250e-04 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 8.5306e-04 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 7.9823e-04 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 7.4773e-04 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 7.0140e-04 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 6.5944e-04 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 6.2125e-04 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 5.8609e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 5.5392e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 5.2446e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 4.9751e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 4.7256e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 4.4965e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 4.2844e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 4.0908e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 3.9112e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 3.7443e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 3.5885e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 3.4440e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 3.3099e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 3.1853e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 3.0692e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 2.9607e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 2.8592e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 2.7646e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 2.6758e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 2.5927e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 2.5149e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 2.4411e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 2.3718e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 2.3064e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 2.2443e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 2.1855e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 2.1302e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 2.0776e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 2.0276e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 1.9805e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 1.9350e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 1.8919e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 1.8506e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 1.8115e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 1.7739e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 1.7379e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 1.7037e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 1.6709e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 1.6395e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 1.6096e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 1.5808e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 1.5531e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 1.5262e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 1.5008e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 1.4760e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 1.4522e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 1.4293e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 1.4073e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 1.3857e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 1.3646e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 1.3446e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 1.3251e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 1.3059e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 1.2876e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 1.2695e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 1.2521e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 1.2354e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 1.2189e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 1.2029e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 1.1874e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 1.1719e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 1.1573e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 1.1427e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 1.1287e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 1.1150e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 1.1016e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 1.0881e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 1.0754e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 1.0627e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 1.0506e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 1.0386e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 1.0269e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cca70fa340>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sanskrit_meow = create_model()\n",
    "model_sanskrit_meow.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(), metrics='accuracy')\n",
    "model_sanskrit_meow.fit(sanskrit_fine_tuning_data, sanskrit_fine_tuning_labels, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d941af68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 38ms/step - loss: 1.5671 - accuracy: 0.4133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5671100616455078, 0.41333332657814026]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sanskrit_meow.evaluate(sanskrit_val_data, sanskrit_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f848ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
